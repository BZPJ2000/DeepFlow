# DeepFlow æ¨¡å‹é€‰æ‹©ä¸è®­ç»ƒæµç¨‹è®¾è®¡

## ç¬¬äº”éƒ¨åˆ†ï¼šæ¨¡å‹é€‰æ‹©ä¸è®­ç»ƒæµç¨‹

---

## 5.1 æ•´ä½“å·¥ä½œæµç¨‹

```
ç”¨æˆ·å¯åŠ¨åº”ç”¨
    â†“
1. ä»»åŠ¡é€‰æ‹©
   - é€‰æ‹©é¢†åŸŸ (NLP/CV/GNN/RL)
   - é€‰æ‹©å­ä»»åŠ¡
    â†“
2. æ¨¡å‹é€‰æ‹©
   - æµè§ˆå¯ç”¨æ¨¡å‹
   - æŸ¥çœ‹æ¨¡å‹è¯¦æƒ…
   - é€‰æ‹©æ¨¡å‹æ¶æ„
    â†“
3. æ•°æ®é…ç½®
   - è®¾ç½®æ•°æ®è·¯å¾„
   - é…ç½®æ•°æ®åˆ†å‰²
   - é€‰æ‹©æ•°æ®å¢å¼º
    â†“
4. è®­ç»ƒé…ç½®
   - é€‰æ‹©æŸå¤±å‡½æ•°
   - é€‰æ‹©è¯„ä¼°æŒ‡æ ‡
   - é€‰æ‹©ä¼˜åŒ–å™¨
   - è®¾ç½®è¶…å‚æ•°
    â†“
5. å¼€å§‹è®­ç»ƒ
   - åˆå§‹åŒ–ç»„ä»¶
   - æ‰§è¡Œè®­ç»ƒå¾ªç¯
   - å®æ—¶ç›‘æ§
    â†“
6. ç»“æœå±•ç¤º
   - è®­ç»ƒæ›²çº¿
   - è¯„ä¼°æŒ‡æ ‡
   - æ¨¡å‹ä¿å­˜
```

---

## 5.2 æ¨¡å‹é€‰æ‹©æœºåˆ¶

### 5.2.1 æ¨¡å‹æµè§ˆç•Œé¢

```python
# ui/pages/2_model_selection.py

import streamlit as st
from deepflow.api.experiment import ExperimentAPI

def render_model_selection():
    """æ¸²æŸ“æ¨¡å‹é€‰æ‹©é¡µé¢"""

    st.title("ğŸ¤– æ¨¡å‹é€‰æ‹©")

    # è·å–å½“å‰ä»»åŠ¡ä¿¡æ¯
    task_info = st.session_state.get('task_info')
    if not task_info:
        st.warning("è¯·å…ˆé€‰æ‹©ä»»åŠ¡")
        return

    # è·å–å¯ç”¨æ¨¡å‹
    api = ExperimentAPI()
    models = api.get_available_models(
        category=task_info['category'],
        subcategory=task_info['subcategory']
    )

    # æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨
    st.subheader(f"å¯ç”¨æ¨¡å‹ ({len(models)})")

    # ç­›é€‰é€‰é¡¹
    col1, col2 = st.columns(2)
    with col1:
        sort_by = st.selectbox(
            "æ’åºæ–¹å¼",
            ["åç§°", "å‚æ•°é‡", "æ¨èåº¦"]
        )
    with col2:
        filter_tags = st.multiselect(
            "æ ‡ç­¾ç­›é€‰",
            ["è½»é‡çº§", "é«˜ç²¾åº¦", "å®æ—¶", "é¢„è®­ç»ƒ"]
        )

    # æ¨¡å‹å¡ç‰‡å±•ç¤º
    for model in models:
        render_model_card(model)
```

### 5.2.2 æ¨¡å‹å¡ç‰‡ç»„ä»¶

```python
# ui/components/model_card.py

import streamlit as st
from deepflow.utils.model_utils import ModelAnalyzer

def render_model_card(model_info):
    """æ¸²æŸ“æ¨¡å‹å¡ç‰‡"""

    with st.expander(f"ğŸ“¦ {model_info.name}", expanded=False):
        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("å‚æ•°é‡", f"{model_info.num_params / 1e6:.2f}M")

        with col2:
            st.metric("æ¨¡å‹å¤§å°", f"{model_info.size_mb:.2f} MB")

        with col3:
            st.metric("æ¨èåº¦", "â­" * model_info.rating)

        # æè¿°
        st.markdown(f"**æè¿°:** {model_info.description}")

        # æ ‡ç­¾
        if model_info.tags:
            st.markdown("**æ ‡ç­¾:** " + " ".join(
                [f"`{tag}`" for tag in model_info.tags]
            ))

        # èµ„æºéœ€æ±‚
        st.markdown("**èµ„æºéœ€æ±‚:**")
        analyzer = ModelAnalyzer()
        requirements = analyzer.estimate_requirements(model_info)

        st.write(f"- æœ€å°æ˜¾å­˜: {requirements['min_memory']} GB")
        st.write(f"- æ¨èæ˜¾å­˜: {requirements['recommended_memory']} GB")
        st.write(f"- è®­ç»ƒæ—¶é—´ä¼°è®¡: {requirements['training_time']}")

        # é€‰æ‹©æŒ‰é’®
        if st.button(f"é€‰æ‹© {model_info.name}", key=f"select_{model_info.name}"):
            st.session_state['selected_model'] = model_info
            st.success(f"å·²é€‰æ‹©æ¨¡å‹: {model_info.name}")
```

---

## 5.3 åŠ¨æ€åŠ è½½æœºåˆ¶

### 5.3.1 ç»„ä»¶åŠ è½½å™¨

```python
# deepflow/core/loader.py

import importlib
from pathlib import Path
from typing import Any, Dict, Optional
import torch.nn as nn

class ComponentLoader:
    """ç»„ä»¶åŠ¨æ€åŠ è½½å™¨"""

    def __init__(self, registry):
        self.registry = registry
        self._cache = {}

    def load_model(self, name: str, **kwargs) -> nn.Module:
        """åŠ è½½æ¨¡å‹"""

        # ä»æ³¨å†Œä¸­å¿ƒè·å–ä¿¡æ¯
        model_info = self.registry.get('models', name)
        if not model_info:
            raise ValueError(f"Model not found: {name}")

        # åŠ¨æ€å¯¼å…¥æ¨¡å—
        module = self._import_module(model_info.module_path)

        # è·å–ç±»
        model_class = getattr(module, model_info.name)

        # éªŒè¯å‚æ•°
        self._validate_params(model_class, kwargs)

        # å®ä¾‹åŒ–
        model = model_class(**kwargs)

        return model

    def load_loss(self, name: str, **kwargs) -> nn.Module:
        """åŠ è½½æŸå¤±å‡½æ•°"""
        loss_info = self.registry.get('losses', name)
        if not loss_info:
            raise ValueError(f"Loss not found: {name}")

        module = self._import_module(loss_info.module_path)
        loss_class = getattr(module, loss_info.name)

        return loss_class(**kwargs)

    def load_metric(self, name: str, **kwargs):
        """åŠ è½½è¯„ä¼°æŒ‡æ ‡"""
        metric_info = self.registry.get('metrics', name)
        if not metric_info:
            raise ValueError(f"Metric not found: {name}")

        module = self._import_module(metric_info.module_path)
        metric_class = getattr(module, metric_info.name)

        return metric_class(**kwargs)

    def _import_module(self, module_path: str):
        """åŠ¨æ€å¯¼å…¥æ¨¡å—"""
        if module_path in self._cache:
            return self._cache[module_path]

        module = importlib.import_module(module_path)
        self._cache[module_path] = module

        return module

    def _validate_params(self, component_class, params: Dict):
        """éªŒè¯å‚æ•°"""
        required = component_class.get_required_params()

        for param_name, param_type in required.items():
            if param_name not in params:
                raise ValueError(f"Missing required parameter: {param_name}")

            if not isinstance(params[param_name], param_type):
                raise TypeError(
                    f"Parameter {param_name} should be {param_type}, "
                    f"got {type(params[param_name])}"
                )
```

---

## 5.4 è®­ç»ƒæµç¨‹è®¾è®¡

### 5.4.1 è®­ç»ƒå™¨æ ¸å¿ƒ

```python
# deepflow/training/trainer.py

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Callable
from pathlib import Path

class Trainer:
    """è®­ç»ƒå™¨"""

    def __init__(
        self,
        model: nn.Module,
        loss_fn: nn.Module,
        optimizer: torch.optim.Optimizer,
        metrics: Dict[str, Callable],
        device: str = 'cuda',
        callbacks: Optional[List] = None
    ):
        self.model = model.to(device)
        self.loss_fn = loss_fn
        self.optimizer = optimizer
        self.metrics = metrics
        self.device = device
        self.callbacks = callbacks or []

        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_metrics': {},
            'val_metrics': {}
        }

    def train(
        self,
        train_loader: DataLoader,
        val_loader: Optional[DataLoader] = None,
        epochs: int = 10,
        save_dir: Optional[Path] = None
    ):
        """è®­ç»ƒæ¨¡å‹"""

        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            train_loss, train_metrics = self._train_epoch(train_loader)

            # éªŒè¯é˜¶æ®µ
            if val_loader:
                val_loss, val_metrics = self._validate_epoch(val_loader)
            else:
                val_loss, val_metrics = None, {}

            # è®°å½•å†å²
            self._update_history(epoch, train_loss, val_loss,
                               train_metrics, val_metrics)

            # æ‰§è¡Œå›è°ƒ
            self._execute_callbacks('on_epoch_end', epoch)

            # ä¿å­˜æ£€æŸ¥ç‚¹
            if save_dir and (epoch + 1) % 5 == 0:
                self._save_checkpoint(save_dir, epoch)

    def _train_epoch(self, train_loader: DataLoader):
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        total_loss = 0
        metric_values = {name: 0 for name in self.metrics}

        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device), target.to(self.device)

            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.loss_fn(output, target)

            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()

            # è®°å½•æŸå¤±
            total_loss += loss.item()

            # è®¡ç®—æŒ‡æ ‡
            for name, metric_fn in self.metrics.items():
                metric_values[name] += metric_fn(output, target).item()

        # å¹³å‡å€¼
        avg_loss = total_loss / len(train_loader)
        avg_metrics = {
            name: value / len(train_loader)
            for name, value in metric_values.items()
        }

        return avg_loss, avg_metrics
```

ä¸‹ä¸€æ®µå°†ç»§ç»­è¯´æ˜éªŒè¯ã€å›è°ƒå’Œé…ç½®ç®¡ç†æœºåˆ¶ã€‚

